import torch
import torch.nn as nn
from diffusers import StableDiffusion3Pipeline, FlowMatchEulerDiscreteScheduler
from safetensors.torch import load_file


# ==================== é€‚é…å‡½æ•°ï¼ˆç‹¬ç«‹ç‰ˆæœ¬ï¼‰====================
def adapt_transformer_for_two_encoders(transformer, new_in_features=2048):
    """
    é€‚é… transformer çš„ context_embedder
    å°†SD3ä»3ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼ˆCLIP-L + CLIP-G + T5ï¼‰é€‚é…ä¸º2ä¸ªï¼ˆCLIP-L + CLIP-Gï¼‰
    """
    old_embedder = transformer.context_embedder
    old_out_features = old_embedder.out_features
    old_in_features = old_embedder.in_features
    
    if old_in_features == new_in_features:
        print(f"âš ï¸  context_embedder already adapted to {new_in_features}")
        return transformer
    
    print(f"ğŸ”§ Adapting context_embedder: {old_in_features} â†’ {new_in_features}")
    
    new_embedder = torch.nn.Linear(
        new_in_features, old_out_features,
        bias=old_embedder.bias is not None,
        dtype=old_embedder.weight.dtype,
        device=old_embedder.weight.device
    )
    
    with torch.no_grad():
        if old_in_features > new_in_features:
            # ä»3ç¼–ç å™¨é™åˆ°2ç¼–ç å™¨ï¼šæˆªå–å‰2048ç»´
            new_embedder.weight.data = old_embedder.weight.data[:, :new_in_features].clone()
        else:
            # ä»2ç¼–ç å™¨å‡åˆ°3ç¼–ç å™¨ï¼ˆä¸å¤ªå¯èƒ½ï¼‰ï¼šå¤åˆ¶ç°æœ‰æƒé‡+åˆå§‹åŒ–æ–°ç»´åº¦
            new_embedder.weight.data[:, :old_in_features] = old_embedder.weight.data.clone()
            torch.nn.init.xavier_uniform_(new_embedder.weight.data[:, old_in_features:])
        
        if new_embedder.bias is not None and old_embedder.bias is not None:
            new_embedder.bias.data = old_embedder.bias.data.clone()
    
    transformer.context_embedder = new_embedder
    print(f"âœ… Context embedder adapted successfully")
    return transformer


# ==================== ä¸»ç¨‹åº ====================
print("="*60)
print("SD3 Fine-tuned Model Inference")
print("="*60)


# 1. åŠ è½½åŸºç¡€æ¨¡å‹
print("\n[1/5] Loading base SD3 model...")
pipe = StableDiffusion3Pipeline.from_single_file(
    "../checkpoint/sd3_medium_incl_clips.safetensors",
    config="sd3_config_cache",
    torch_dtype=torch.float16,
    local_files_only=True,
    text_encoder_3=None,
    tokenizer_3=None
)
pipe = pipe.to("cuda")
print(f"âœ“ Base model loaded")
print(f"  Scheduler: {pipe.scheduler.__class__.__name__}")


# 2. è®¾ç½®æ­£ç¡®çš„ schedulerï¼ˆå…³é”®ï¼ï¼‰
print("\n[2/5] Setting up FlowMatchEulerDiscreteScheduler...")
pipe.scheduler = FlowMatchEulerDiscreteScheduler.from_config(
    pipe.scheduler.config,
    shift=3.0  # SD3 Medium çš„æ¨èå€¼
)
print(f"âœ“ Scheduler configured: {pipe.scheduler.__class__.__name__}")




# 4. åŠ è½½å¾®è°ƒæƒé‡
print("\n[4/5] Loading fine-tuned weights...")
ft_path = "/CSTemp/yjl/R-SD/4/output_full_fast/checkpoint-10000/diffusion_pytorch_model.safetensors"
state_dict = load_file(ft_path)


missing, unexpected = pipe.transformer.load_state_dict(state_dict, strict=False)
print(f"  Missing keys: {len(missing)} - {missing[:3] if missing else '[]'}")
print(f"  Unexpected keys: {len(unexpected)} - {unexpected[:3] if unexpected else '[]'}")


# éªŒè¯æƒé‡ç¡®å®æ”¹å˜äº†
finetuned_weight_sample = pipe.transformer.transformer_blocks[0].attn.to_q.weight[0, 0].item()
print(f"\n  Weight verification:")
print(f"    Original: {original_weight_sample.item():.6f}")
print(f"    Fine-tuned: {finetuned_weight_sample:.6f}")
print(f"    Changed: {'âœ“ YES' if abs(original_weight_sample.item() - finetuned_weight_sample) > 1e-6 else 'âœ— NO - WARNING!'}")


if len(missing) == 0 and len(unexpected) == 0:
    print("âœ“ Fine-tuned weights loaded successfully!")
else:
    print("âš ï¸ Warning: Key mismatch detected")



# 3. é€‚é… transformer
print("\n[3/5] Adapting transformer for 2-encoder input...")
# ä¿å­˜åŸå§‹æƒé‡ç”¨äºå¯¹æ¯”
original_weight_sample = pipe.transformer.transformer_blocks[0].attn.to_q.weight[0, 0].clone()
pipe.transformer = adapt_transformer_for_two_encoders(pipe.transformer, new_in_features=2048)


# 5. æ¨ç†ç”Ÿæˆ
print("\n[5/5] Generating image...")
print("="*60)


prompt = "a high quality X-ray image of scoliosis"
negative_prompt = "blurry, low quality, distorted"


# ä½¿ç”¨æ›´å¤šæ­¥æ•°å’Œæ›´é«˜çš„ guidance
image = pipe(
    prompt,
    negative_prompt=negative_prompt,
    num_inference_steps=50,  # å¢åŠ æ­¥æ•°
    guidance_scale=7.0,
    generator=torch.Generator(device="cuda").manual_seed(42)  # å›ºå®šéšæœºç§å­
).images[0]


image.save("gene.png")
print("\nâœ… Image saved as gene.png")


# é¢å¤–ï¼šç”Ÿæˆå¤šå¼ å¯¹æ¯”
print("\nGenerating comparison images...")
for i, steps in enumerate([28, 50, 100]):
    img = pipe(
        prompt,
        negative_prompt=negative_prompt,
        num_inference_steps=steps,
        guidance_scale=7.0,
        generator=torch.Generator(device="cuda").manual_seed(42)
    ).images[0]
    img.save(f"gene_steps{steps}.png")
    print(f"  Saved gene_steps{steps}.png")


print("\n" + "="*60)
print("Done! Check the generated images.")
print("="*60)
